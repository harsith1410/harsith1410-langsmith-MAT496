# Module 1

* In video 1 it explained about what is tracing and the importance of tracing as it helps in easily seeing where the code is actually struggling in a pictorial manner
---
* In video 2 it was explained abt the different running methods and how their outputs were rendered but it seems that the difference in rendering has been reduced these days
* * It explained abt the LLM, Chain, Tool and Retriver runtype
---
* In video 3 we saw abt a few different methods for doing the tracing other than the traceable annotation
  * We saw that instead of the traceable annotation we used
    * trace method 
    * the langraph which had an inbuilt tracing method that was set in the env
    * using <b>wrap_openai</b> that automatically tracks each call done by the langchain 
    * Another method was the RUNTREE which was not explained a lot as they were more advanced
---
* In video 4 we say about how we can give thread id that would give us a look that it is similar to that of a actual chatbot where there are continuous chats based on previous chats asking questions
---

# Module 2

* In Video 1 what we did was we created datasets that have a question and gives an output for the given question
  * We did by sending the example data set thru the code
  * We also did by adding manually on the website
  * We did by AI generation
  
  * We used to split and to filter the examples 
  ![img.png](img.png)

---

* In video 2 we used a comparator that comes in with the Langchain modules that compare the preferred output with a sample output that we got by comparing and scoring them
  * These comparators are called as evaluators
  * We also tried by comparing manually on the langsmith UI website

---

* 
